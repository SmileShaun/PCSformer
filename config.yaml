model:
  model_resolution: 256
  in_channels: 3
  embed_dim: [48, 96, 96, 96, 48]
  depth: [4, 6, 8, 6, 4]
  split_size: [1, 2, 8, 2, 1]
  proxy_downscale: [4, 2, 2]
  num_heads: [4, 8, 8, 4, 4]
  mlp_ratio: 4.
  qkv_bias: True
  attn_drop_rate: 0.
  proj_drop_rata: 0.
  drop_path_rate: 0.
  num_refinement_blocks: 5
  refinement_block_dim: 48

train:
  train_batch_size: 10
  val_batch_size: 1
  train_patch_size: 256
  val_patch_size: 256
  edge_decay: 0
  only_h_flip: False
  optimizer: 'adamw'
  lr: 0.00002
  epochs: 100
  eval_freq: 1
  num_workers: 4
  no_autocast: True
  train_data_dir: ''
  val_data_dir: ''
  weight_save_dir: 'weights'
  log_dir: 'logs'